# ai-rag-lab
Building Retrieval Augmented Generation (RAG) systems from scratch to real-time AI assistants using embeddings, FAISS, and LangChain.

# AI RAG Lab â€“ From Scratch to Real-Time AI Assistant

This repository documents my journey of learning and building **Retrieval Augmented Generation (RAG)** systems from scratch and progressing toward real-world AI applications using **LangChain, Vector Databases, and LLMs**.

The goal is not to copy tutorials, but to deeply understand how RAG works internally and apply it to build practical AI systems.

---

## Learning Roadmap

This repo is structured as a progressive journey through four connected AI projects:

### ğŸ”¹ Project 1 â€” RAG From Scratch (No LangChain)
Understand RAG at the fundamental level using:
- Embeddings
- Vector search (FAISS)
- Chunking
- Context injection into LLM

> Build RAG using pure Python + OpenAI + FAISS.

---

### ğŸ”¹ Project 2 â€” Multi-Document RAG with LangChain
Introduce LangChain after understanding RAG basics:
- Document loaders
- Text splitters
- Vector stores
- Chains and prompts

> Build a RAG system that works across multiple documents.

---

### ğŸ”¹ Project 3 â€” Personal AI Data Analyst
Combine RAG with data analysis:
- Upload CSV
- Ask questions
- AI analyzes data using Pandas + LLM reasoning

> Build an AI assistant that acts like a data analyst.

---

### ğŸ”¹ Project 4 â€” Real-Time AI Assistant (Streamlit App)
Turn everything into an interactive application:
- Ask questions from documents/data in real-time
- Deploy as a usable AI tool

> Build a complete AI application.

---

## ğŸ§± Repository Structure

